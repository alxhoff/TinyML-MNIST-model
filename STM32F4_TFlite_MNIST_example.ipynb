{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STM32F4 TFlite MNIST example",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPwboVxnQ51Z12i7SvNJ8yE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alxhoff/TinyML-MNIST-model/blob/master/STM32F4_TFlite_MNIST_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_q-FH0dgMQq",
        "colab_type": "text"
      },
      "source": [
        "This example will perform character recognition through user input into the touch screen of an STM3240G-Evaluation board using the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcNx6RbVg3cc",
        "colab_type": "code",
        "outputId": "5e3b049e-61d1-4556-e67b-32acc243b85d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "!apt-get install -y xxd\n",
        "\n",
        "#! pip uninstall -y tensorflow\n",
        "#! pip install -q tf-nightly\n",
        "! pip install -q tensorflow-model-optimization\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "(images_train, labels_train), (images_test, labels_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xxd is already the newest version (2:8.0.1453-1ubuntu1.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y2hcinVg4Ws",
        "colab_type": "text"
      },
      "source": [
        "Importing Tensorflow allows you to use its API to load the MNIST dataset. It should be noted that we need to use TF version <1.14 as this version includes the fully connected operation version 3 which is incompatible with the micro interpreters version 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnCKuVlVjRhX",
        "colab_type": "code",
        "outputId": "4038cee1-f1d7-4143-b431-0bc376feb025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "test_index = 12345\n",
        "print(labels_train[test_index])\n",
        "plt.imshow(images_train[test_index], cmap='Greys')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fba800d9f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-76bBO2rlABd",
        "colab_type": "text"
      },
      "source": [
        "The input of the neural network needs to know the input shape that it is going to be fed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWwrc29FlEgQ",
        "colab_type": "code",
        "outputId": "d5db8fc5-1a01-4a90-d5bf-c6ce53644035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_shape = images_train.shape\n",
        "print(\"{} images, each with shape of {} pixels x {} pixels\".format(input_shape[0], input_shape[1], input_shape[2]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 images, each with shape of 28 pixels x 28 pixels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn-3cvuymAWT",
        "colab_type": "text"
      },
      "source": [
        "The input shape for the model must be reshaped to 4D as the current shape does not show that each pixel is a 1D array where only the greyscale value (0-255) is stored. The input tensor's shape will be 3D as it will take a single-channel image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOZnWmzUmTuI",
        "colab_type": "code",
        "outputId": "e6fd95b3-658a-44d0-9049-a10e056d1fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "images_train = images_train.reshape(images_train.shape[0], images_train.shape[1], images_train.shape[2], 1)\n",
        "images_test = images_test.reshape(images_test.shape[0], images_test.shape[1], images_test.shape[2], 1)\n",
        "input_tensor_shape = (images_test.shape[1], images_test.shape[2], 1)\n",
        "print(\"Input shape: {}\".format(input_shape))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: (60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjPMYztkm0tg",
        "colab_type": "text"
      },
      "source": [
        "The greyscale values stores in the images' pixels are 8 bit values and need to be normalized into floats between 0-1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adD13BYinHlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_train = images_train.astype('float32')\n",
        "images_test = images_test.astype('float32')\n",
        "images_train /= 255\n",
        "images_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3oXnIHunXvs",
        "colab_type": "text"
      },
      "source": [
        "Now the convolutional NN that we will use to classify the input images taken from the touch screen will have the following layer structure\n",
        "\n",
        "1. Conv2D\n",
        "2. MaxPooling2D\n",
        "3. Flatten\n",
        "4. Dense\n",
        "5. Dropout\n",
        "11. Dense\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-2aWbOirRCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(28, kernel_size=(3,3), input_shape=input_tensor_shape))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(keras.layers.Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model.add(keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "model2 = keras.Sequential()\n",
        "\n",
        "model2.add(keras.layers.Conv2D(12, kernel_size=(3,3), input_shape=input_tensor_shape))\n",
        "model2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(keras.layers.Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model2.add(keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "model3 = keras.Sequential()\n",
        "\n",
        "model3.add(keras.layers.Conv2D(12, kernel_size=(3,3), strides=(2,2), input_shape=input_tensor_shape))\n",
        "model3.add(keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "#model3.add(keras.layers.Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model3.add(keras.layers.Reshape((16,12,1)))\n",
        "model3.add(keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "#model3.add(keras.layers.MaxPooling1D(pool_size=6, padding='valid', data_format='channels_last'))\n",
        "model3.add(keras.layers.Flatten())\n",
        "model3.add(keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "model4 = keras.Sequential()\n",
        "\n",
        "model4.add(keras.layers.Conv2D(12, kernel_size=(3,3), strides=(2,2), input_shape=input_tensor_shape))\n",
        "model4.add(keras.layers.Reshape( (13, 13, 12, 1)))\n",
        "model4.add(keras.layers.MaxPooling3D(pool_size=(6, 3,3)))\n",
        "model4.add(keras.layers.Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model4.add(keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "model5 = keras.Sequential()\n",
        "\n",
        "model5.add(keras.layers.Conv2D(12, kernel_size=(3,3), strides=(2,2), input_shape=input_tensor_shape))\n",
        "model5.add(keras.layers.Reshape( (338, 6, 1)))\n",
        "model5.add(keras.layers.MaxPooling2D(pool_size=(26, 3)))\n",
        "model5.add(keras.layers.Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model5.add(keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "quantized_model5 = quantize_model(model5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5CLXe63rRPf",
        "colab_type": "text"
      },
      "source": [
        "The Conv2D layer extracts features from the input image using filters that slide across the input image. In this case we will use 28 different filters to extract a large number of unique features that will then be used to classify each image in the later layers. Thus the output of this layer will have the shape (28, 28, 1, 28)\n",
        "\n",
        "MaxPooling2D is used to reduce the output size of the convolutional layer by reducing each 2 x 2 unique chunk of the output down in to a singular value, this reducing the output's size by a factor of 4. This will reduce our (28, 28, 1, 28) tensor down to a (7, 7, 1, 28) tensor.\n",
        "\n",
        "The Flatten layer then takes this 2D array (our image) and shapes it into a single dimension (1372).\n",
        "\n",
        "The following Dense layer reduces the input 1372 values down into 128 classes, taking the first steps in classifying the image into on of the 10 output classes (0-9). This is done using the relu activation function.\n",
        "\n",
        "The Dropout layer sets 20% of the tensor's values to 0 so as to reduce overfitting.\n",
        "\n",
        "Finally the last Dense layer reduces the output value down to the 10 classes, each representing a digit between 0 and 9. This is done using the softmax activation function which makes the outputs a set of probabilities summing to 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrG75fkHxdkN",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXWfgL0LxS3o",
        "colab_type": "code",
        "outputId": "54b1a8d1-cbe6-4a49-8471-e941a8e49f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model4.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model5.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "quantized_model5.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 10\n",
        "\n",
        "print(\"Model 1\")\n",
        "history = model.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "model.summary()\n",
        "\n",
        "print(\"Model 2\")\n",
        "history2 = model2.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "model2.summary()\n",
        "\n",
        "print(\"Model 3\")\n",
        "history3 = model3.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "model3.summary()\n",
        "\n",
        "print(\"Model 4\")\n",
        "history4 = model4.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "model4.summary()\n",
        "\n",
        "print(\"Model 5\")\n",
        "history5 = model5.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "model5.summary()\n",
        "\n",
        "print(\"Model 5 Quantized\")\n",
        "history5_q = quantized_model5.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "quantized_model5.summary()\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 3\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.8011 - accuracy: 0.4294\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.8429 - accuracy: 0.7426\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.6563 - accuracy: 0.7912\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.5826 - accuracy: 0.8138\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.8267\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.8335\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.5012 - accuracy: 0.8393\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.4885 - accuracy: 0.8432\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.4783 - accuracy: 0.8465\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.4695 - accuracy: 0.8501\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_46 (Conv2D)           (None, 13, 13, 12)        120       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 4, 4, 12)          0         \n",
            "_________________________________________________________________\n",
            "reshape_19 (Reshape)         (None, 16, 12, 1)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 5, 4, 1)           0         \n",
            "_________________________________________________________________\n",
            "flatten_45 (Flatten)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 330\n",
            "Trainable params: 330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNtcEcKuxgYb",
        "colab_type": "text"
      },
      "source": [
        "Now we can evaluate our trained model using the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4zrA9hNxkAC",
        "colab_type": "code",
        "outputId": "00d6fc42-cc52-4222-e73f-fdf188a0b807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "res = model.evaluate(images_test, labels_test)\n",
        "print(\"Model1 has an accuracy of {0:.2f}%\".format(res[1] * 100))\n",
        "\n",
        "res = model2.evaluate(images_test, labels_test)\n",
        "print(\"Model2 has an accuracy of {0:.2f}%\".format(res[1] * 100))\n",
        "\n",
        "res = model3.evaluate(images_test, labels_test)\n",
        "print(\"Model3 has an accuracy of {0:.2f}%\".format(res[1] * 100))\n",
        "\n",
        "res = model4.evaluate(images_test, labels_test)\n",
        "print(\"Model4 has an accuracy of {0:.2f}%\".format(res[1] * 100))\n",
        "\n",
        "res = model5.evaluate(images_test, labels_test)\n",
        "print(\"Model5 has an accuracy of {0:.2f}%\".format(res[1] * 100))\n",
        "\n",
        "res = quantized_model5.evaluate(images_test, labels_test)\n",
        "print(\"Quantized model5 has an accuracy of {0:.2f}%\".format(res[1] * 100))\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 2.3092 - accuracy: 0.0633\n",
            "Model1 has an accuracy of 6.33%\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 2.3353 - accuracy: 0.0652\n",
            "Model2 has an accuracy of 6.52%\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4439 - accuracy: 0.8602\n",
            "Model3 has an accuracy of 86.02%\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 2.3653 - accuracy: 0.1192\n",
            "Model4 has an accuracy of 11.92%\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 2.5546 - accuracy: 0.1152\n",
            "Model5 has an accuracy of 11.52%\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 2.5345 - accuracy: 0.1011\n",
            "Quantized model5 has an accuracy of 10.11%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeIhxRzT3w7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#best_model = quantized_model5\n",
        "best_model = model3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytu4OjmCzMIT",
        "colab_type": "text"
      },
      "source": [
        "Now we will need to convert and save our model into a downloadable file that will be appropriate for a microcontroller. This is done using the TensorFlow Lite Converter. The `TFLITE_BUILTINS` option tells the converter to only use TensorFlow Lite built in operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ8FDCOczYMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"MNIST_model_no_optimizations.tflite\", \"wb\").write(tflite_model)\n",
        "!xxd -i MNIST_model_no_optimizations.tflite > MNIST_model_no_optimizations.cc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it6Eoe3x1B0U",
        "colab_type": "text"
      },
      "source": [
        "Now we will be running this model on a constrained device and as such we will need to perform quantization and optimizations to reduce the size of the model. The optimizations that TensorFlow offers are detailed [here](https://www.tensorflow.org/lite/performance/model_optimization). Also see [here](https://www.tensorflow.org/model_optimization/guide/quantization/training) for more information on quanitazation aware training and [here](https://www.tensorflow.org/lite/performance/post_training_quantization) for information on post-training quantization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW9_WVtz1K5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"MNIST_optimized_for_size.tflite\", \"wb\").write(tflite_model)\n",
        "!xxd -i MNIST_optimized_for_size.tflite > MNIST_optimized_for_size.cc\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"MNIST_default_optimizations.tflite\", \"wb\").write(tflite_model)\n",
        "!xxd -i MNIST_default_optimizations.tflite > MNIST_default_optimizations.cc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ysFrDZq13Zx",
        "colab_type": "text"
      },
      "source": [
        "These optimizations reduced the file size significantly but we can do better. Enforcing full integer quantization for all operations as well as ensuring all model math is quantized to 8-bit. Doing so requires a representative dataset that can be used to evaluate optimizations made by the converter. The representative dataset must be a python iterator.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7WgyAFXCvk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def representative_dataset_gen():\n",
        "  for image in images_test:\n",
        "    array = np.array(image)\n",
        "    array = np.expand_dims(array, axis = 0)\n",
        "    yield ([array])\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"MNIST_full_quanitization.tflite\", \"wb\").write(tflite_model)\n",
        "!xxd -i MNIST_full_quanitization.tflite > MNIST_full_quanitization.cc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JBLhgQ-2PXr",
        "colab_type": "text"
      },
      "source": [
        "This file needs to now be included in our microcontroller project and as such must be in a form that is easily usable on a device without a file system. xxd can be used to convert the model into a C source file where the model is stored as a byte array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Encu0Li72cmB",
        "colab_type": "code",
        "outputId": "69ec3693-0e38-405a-eeda-605482ee411a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!xxd -i MNIST_full_quanitization.tflite > MNIST_full_quanitization.cc\n",
        "!cat MNIST_full_quanitization.cc"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unsigned char MNIST_full_quanitization_tflite[] = {\n",
            "  0x14, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xda, 0xfc, 0xff, 0xff,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x44, 0x0e, 0x00, 0x00, 0x10, 0x03, 0x00, 0x00,\n",
            "  0xf8, 0x02, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00,\n",
            "  0xdc, 0x02, 0x00, 0x00, 0xc8, 0x02, 0x00, 0x00, 0x9c, 0x02, 0x00, 0x00,\n",
            "  0x58, 0x02, 0x00, 0x00, 0x34, 0x02, 0x00, 0x00, 0x50, 0x01, 0x00, 0x00,\n",
            "  0xcc, 0x00, 0x00, 0x00, 0x88, 0x00, 0x00, 0x00, 0x7c, 0x00, 0x00, 0x00,\n",
            "  0x68, 0x00, 0x00, 0x00, 0x54, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,\n",
            "  0x2c, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0xe4, 0xf2, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0xf4, 0xf2, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0xf3, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x14, 0xf3, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x24, 0xf3, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x34, 0xf3, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x44, 0xf3, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x06, 0xfd, 0xff, 0xff,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00, 0x1e, 0x17, 0x00, 0x00,\n",
            "  0x92, 0xea, 0xff, 0xff, 0xbb, 0x10, 0x00, 0x00, 0x57, 0x0f, 0x00, 0x00,\n",
            "  0x28, 0xda, 0xff, 0xff, 0x4a, 0x11, 0x00, 0x00, 0xa5, 0xde, 0xff, 0xff,\n",
            "  0x2c, 0xcf, 0xff, 0xff, 0xd7, 0x34, 0x00, 0x00, 0xe4, 0xb1, 0xff, 0xff,\n",
            "  0xbc, 0xca, 0xff, 0xff, 0xda, 0x3f, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x46, 0xfd, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x6c, 0x00, 0x00, 0x00,\n",
            "  0xb9, 0xef, 0x31, 0xfe, 0xee, 0xf7, 0xe3, 0x81, 0xe1, 0x19, 0xf7, 0x0d,\n",
            "  0x46, 0x2b, 0x26, 0x81, 0x0e, 0x0f, 0xf3, 0x58, 0x71, 0x86, 0x22, 0x02,\n",
            "  0x81, 0xc2, 0x94, 0xf0, 0x18, 0x73, 0x81, 0x11, 0x53, 0xab, 0x41, 0x7c,\n",
            "  0x35, 0x3f, 0x3d, 0xe3, 0x81, 0x35, 0x86, 0x73, 0x98, 0xfd, 0xa0, 0x81,\n",
            "  0xe4, 0x91, 0xe5, 0xca, 0x00, 0xce, 0x7c, 0x49, 0xba, 0xf1, 0x61, 0x73,\n",
            "  0x81, 0xb3, 0x70, 0x11, 0xb6, 0x12, 0x2f, 0xb9, 0xdf, 0xab, 0x81, 0x1e,\n",
            "  0x1c, 0x02, 0x01, 0x6e, 0x2d, 0x7f, 0x2c, 0xcb, 0x2d, 0x7f, 0x20, 0x0d,\n",
            "  0x0c, 0x17, 0xe8, 0xa7, 0xbd, 0x98, 0x9c, 0x82, 0x8f, 0x39, 0xfa, 0x1d,\n",
            "  0x7f, 0x47, 0x70, 0x0c, 0xb5, 0x81, 0x07, 0x0a, 0x1d, 0xea, 0xad, 0x40,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xc6, 0xfd, 0xff, 0xff,\n",
            "  0x04, 0x00, 0x00, 0x00, 0xc8, 0x00, 0x00, 0x00, 0xf2, 0xf5, 0x00, 0x03,\n",
            "  0xa9, 0x21, 0x00, 0x0a, 0x1d, 0x1c, 0x2e, 0xf8, 0xc0, 0xff, 0xc2, 0xb9,\n",
            "  0x2a, 0xd0, 0x12, 0x31, 0xe0, 0x17, 0xfa, 0xbf, 0x1c, 0xf8, 0xe8, 0xe0,\n",
            "  0x8d, 0x2e, 0xe1, 0xbe, 0xcf, 0x3a, 0xd3, 0x98, 0x07, 0x34, 0x02, 0xcc,\n",
            "  0x2a, 0xed, 0x2d, 0x0b, 0x54, 0xcb, 0x0e, 0xf6, 0x09, 0x1e, 0x16, 0xce,\n",
            "  0xd4, 0xe0, 0xc7, 0x54, 0x29, 0xe4, 0x09, 0x00, 0x03, 0xf1, 0x18, 0x33,\n",
            "  0x5c, 0xb7, 0xf0, 0xfc, 0xde, 0xfe, 0x02, 0x1a, 0x44, 0xf1, 0x1d, 0xfa,\n",
            "  0xec, 0xc9, 0xfc, 0x4c, 0xc0, 0x06, 0x11, 0xc6, 0xb6, 0x36, 0xf5, 0xf5,\n",
            "  0xe5, 0x33, 0x9f, 0xbb, 0x1c, 0x14, 0x2c, 0x30, 0xe9, 0xf7, 0xd3, 0x81,\n",
            "  0xf7, 0xf5, 0xec, 0xfd, 0xd7, 0x15, 0xf0, 0x12, 0x2c, 0x92, 0xf2, 0x10,\n",
            "  0x3e, 0xfe, 0x27, 0x09, 0x0c, 0xcc, 0x0e, 0x44, 0xe2, 0x43, 0xef, 0xfa,\n",
            "  0xb1, 0x1f, 0xd0, 0xf3, 0xc8, 0xd4, 0x99, 0x04, 0xd3, 0x20, 0x04, 0x3a,\n",
            "  0x29, 0xce, 0x34, 0x12, 0xf6, 0xf0, 0xe3, 0xec, 0x2c, 0x02, 0x3a, 0x02,\n",
            "  0x16, 0x20, 0x23, 0x21, 0xf1, 0x18, 0x9f, 0xdd, 0xbf, 0x0f, 0xc2, 0xb3,\n",
            "  0xf1, 0xe7, 0x0c, 0x1d, 0xf0, 0xfd, 0x29, 0x00, 0xf5, 0xea, 0x01, 0x0b,\n",
            "  0xe9, 0xea, 0x28, 0x02, 0xf2, 0x00, 0x10, 0x0e, 0xef, 0xc2, 0x8f, 0x34,\n",
            "  0xda, 0x26, 0xdd, 0xf8, 0xf7, 0x02, 0x1d, 0x15, 0x1a, 0x0d, 0x16, 0x16,\n",
            "  0xcd, 0xfd, 0xcc, 0x9c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0xa6, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0xc6, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00,\n",
            "  0x19, 0xfc, 0xff, 0xff, 0xf2, 0x03, 0x00, 0x00, 0x91, 0x00, 0x00, 0x00,\n",
            "  0x20, 0xff, 0xff, 0xff, 0xe6, 0xff, 0xff, 0xff, 0xd8, 0x00, 0x00, 0x00,\n",
            "  0xc2, 0xff, 0xff, 0xff, 0x3e, 0x01, 0x00, 0x00, 0xce, 0xfe, 0xff, 0xff,\n",
            "  0x96, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x06, 0xff, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x74, 0xf5, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x84, 0xf5, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x4d, 0x4c, 0x49, 0x52,\n",
            "  0x20, 0x43, 0x6f, 0x6e, 0x76, 0x65, 0x72, 0x74, 0x65, 0x64, 0x2e, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00,\n",
            "  0x18, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00,\n",
            "  0x0e, 0x00, 0x00, 0x00, 0x60, 0x02, 0x00, 0x00, 0x54, 0x02, 0x00, 0x00,\n",
            "  0x48, 0x02, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x6d, 0x61, 0x69, 0x6e, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x09, 0x00, 0x00, 0x00, 0x0c, 0x02, 0x00, 0x00, 0xb4, 0x01, 0x00, 0x00,\n",
            "  0x50, 0x01, 0x00, 0x00, 0x18, 0x01, 0x00, 0x00, 0xd4, 0x00, 0x00, 0x00,\n",
            "  0x9c, 0x00, 0x00, 0x00, 0x64, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x22, 0xfe, 0xff, 0xff, 0x06, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x0f, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
            "  0xfa, 0xfe, 0xff, 0xff, 0x00, 0x00, 0x00, 0x09, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x24, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x80, 0x3f, 0x01, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0xa6, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x08, 0x03, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x7c, 0xf6, 0xff, 0xff,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x0b, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0xae, 0xfe, 0xff, 0xff, 0x02, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00,\n",
            "  0x07, 0x00, 0x14, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x05,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x2c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x8a, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x22, 0xff, 0xff, 0xff,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00,\n",
            "  0x1a, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x07, 0x00, 0x14, 0x00,\n",
            "  0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x05, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x3c, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x07, 0x00, 0x08, 0x00, 0x0c, 0x00,\n",
            "  0x10, 0x00, 0x14, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00,\n",
            "  0x16, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x07, 0x00, 0x10, 0x00,\n",
            "  0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x30, 0x00, 0x00, 0x00,\n",
            "  0x24, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0a, 0x00,\n",
            "  0x10, 0x00, 0x07, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x01, 0x02, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x0a, 0x00, 0x10, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00,\n",
            "  0x0a, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x0f, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x24, 0x08, 0x00, 0x00, 0xbc, 0x07, 0x00, 0x00,\n",
            "  0x34, 0x07, 0x00, 0x00, 0xe8, 0x06, 0x00, 0x00, 0x60, 0x06, 0x00, 0x00,\n",
            "  0xf4, 0x04, 0x00, 0x00, 0x18, 0x04, 0x00, 0x00, 0x9c, 0x03, 0x00, 0x00,\n",
            "  0x08, 0x03, 0x00, 0x00, 0x74, 0x02, 0x00, 0x00, 0xe0, 0x01, 0x00, 0x00,\n",
            "  0x54, 0x01, 0x00, 0x00, 0xd0, 0x00, 0x00, 0x00, 0x74, 0x00, 0x00, 0x00,\n",
            "  0x3c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xd8, 0xff, 0xff, 0xff,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x49, 0x64, 0x65, 0x6e, 0x74, 0x69, 0x74, 0x79, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x0c, 0x00, 0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x0f, 0x00, 0x00, 0x00, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x34,\n",
            "  0x36, 0x5f, 0x69, 0x6e, 0x70, 0x75, 0x74, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x92, 0xf8, 0xff, 0xff, 0x00, 0x00, 0x00, 0x09,\n",
            "  0x44, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x6c, 0xf9, 0xff, 0xff, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x80, 0xff, 0xff, 0xff,\n",
            "  0xff, 0xff, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x3b,\n",
            "  0x0d, 0x00, 0x00, 0x00, 0x49, 0x64, 0x65, 0x6e, 0x74, 0x69, 0x74, 0x79,\n",
            "  0x5f, 0x69, 0x6e, 0x74, 0x38, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0xea, 0xf8, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x6c, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
            "  0x40, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xdc, 0xf8, 0xff, 0xff,\n",
            "  0x2c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x25, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xaf, 0x9b, 0xfc, 0x3d,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xcc, 0xa8, 0x31, 0x41, 0x01, 0x00, 0x00, 0x00,\n",
            "  0xad, 0xca, 0xa2, 0xc1, 0x1e, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
            "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x34, 0x36, 0x2f, 0x64, 0x65,\n",
            "  0x6e, 0x73, 0x65, 0x5f, 0x35, 0x34, 0x2f, 0x42, 0x69, 0x61, 0x73, 0x41,\n",
            "  0x64, 0x64, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x0a, 0x00, 0x00, 0x00, 0x6a, 0xf9, 0xff, 0xff, 0x00, 0x00, 0x00, 0x09,\n",
            "  0x74, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x44, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x5c, 0xf9, 0xff, 0xff, 0x30, 0x00, 0x00, 0x00,\n",
            "  0x24, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x7a, 0x3b, 0x3d,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xdf, 0xa1, 0xb2, 0x40, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x2e, 0xdb, 0xc2, 0xc0, 0x20, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
            "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x34, 0x36, 0x2f, 0x66, 0x6c,\n",
            "  0x61, 0x74, 0x74, 0x65, 0x6e, 0x5f, 0x34, 0x35, 0x2f, 0x52, 0x65, 0x73,\n",
            "  0x68, 0x61, 0x70, 0x65, 0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0xf2, 0xf9, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x74, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00,\n",
            "  0x40, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xe4, 0xf9, 0xff, 0xff,\n",
            "  0x2c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x7a, 0x3b, 0x3d,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xdf, 0xa1, 0xb2, 0x40, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x2e, 0xdb, 0xc2, 0xc0, 0x26, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
            "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x34, 0x36, 0x2f, 0x6d, 0x61,\n",
            "  0x78, 0x5f, 0x70, 0x6f, 0x6f, 0x6c, 0x69, 0x6e, 0x67, 0x32, 0x64, 0x5f,\n",
            "  0x34, 0x32, 0x2f, 0x4d, 0x61, 0x78, 0x50, 0x6f, 0x6f, 0x6c, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x82, 0xfa, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x74, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x44, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x74, 0xfa, 0xff, 0xff,\n",
            "  0x30, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x7a, 0x3b, 0x3d, 0x01, 0x00, 0x00, 0x00, 0xdf, 0xa1, 0xb2, 0x40,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x2e, 0xdb, 0xc2, 0xc0, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x34,\n",
            "  0x36, 0x2f, 0x72, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x5f, 0x31, 0x39,\n",
            "  0x2f, 0x52, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x12, 0xfb, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x74, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00,\n",
            "  0x40, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x04, 0xfb, 0xff, 0xff,\n",
            "  0x2c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x7a, 0x3b, 0x3d,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xdf, 0xa1, 0xb2, 0x40, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x2e, 0xdb, 0xc2, 0xc0, 0x26, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
            "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x34, 0x36, 0x2f, 0x6d, 0x61,\n",
            "  0x78, 0x5f, 0x70, 0x6f, 0x6f, 0x6c, 0x69, 0x6e, 0x67, 0x32, 0x64, 0x5f,\n",
            "  0x34, 0x31, 0x2f, 0x4d, 0x61, 0x78, 0x50, 0x6f, 0x6f, 0x6c, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0xa2, 0xfb, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x5c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x44, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x94, 0xfb, 0xff, 0xff,\n",
            "  0x30, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x7a, 0x3b, 0x3d, 0x01, 0x00, 0x00, 0x00, 0xdf, 0xa1, 0xb2, 0x40,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x2e, 0xdb, 0xc2, 0xc0, 0x0b, 0x00, 0x00, 0x00,\n",
            "  0x74, 0x66, 0x6c, 0x2e, 0x63, 0x6f, 0x6e, 0x76, 0x5f, 0x32, 0x64, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
            "  0x0d, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x1a, 0xfc, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x02, 0xc8, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00,\n",
            "  0xac, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xf4, 0xfc, 0xff, 0xff,\n",
            "  0x6c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0xcd, 0xdf, 0x13, 0x37, 0x5e, 0xa6, 0x75, 0x37,\n",
            "  0x1b, 0x93, 0x71, 0x38, 0x42, 0x03, 0x4f, 0x38, 0xd2, 0xb4, 0xe6, 0x36,\n",
            "  0xc1, 0x65, 0xc7, 0x36, 0x8a, 0x5c, 0x29, 0x38, 0x81, 0x63, 0x0f, 0x37,\n",
            "  0xd9, 0x6b, 0x5a, 0x37, 0xba, 0x5b, 0x9c, 0x37, 0x61, 0x55, 0x2c, 0x38,\n",
            "  0x39, 0xdc, 0x0b, 0x37, 0x0c, 0x00, 0x00, 0x00, 0x73, 0x74, 0x64, 0x2e,\n",
            "  0x63, 0x6f, 0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0xf2, 0xfc, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x4c, 0x01, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
            "  0x20, 0x01, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xe4, 0xfc, 0xff, 0xff,\n",
            "  0xe0, 0x00, 0x00, 0x00, 0xa8, 0x00, 0x00, 0x00, 0x70, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0xed, 0x4b, 0x13, 0x3b, 0xb7, 0xb0, 0x74, 0x3b,\n",
            "  0x87, 0xa1, 0x70, 0x3c, 0x3e, 0x34, 0x4e, 0x3c, 0x1c, 0xce, 0xe5, 0x3a,\n",
            "  0x5a, 0x9e, 0xc6, 0x3a, 0x2d, 0xb3, 0x28, 0x3c, 0x1d, 0xd4, 0x0e, 0x3b,\n",
            "  0x6c, 0x91, 0x59, 0x3b, 0x5e, 0xbf, 0x9b, 0x3b, 0x0b, 0xa9, 0x2b, 0x3c,\n",
            "  0x5c, 0x50, 0x0b, 0x3b, 0x0c, 0x00, 0x00, 0x00, 0x98, 0x9d, 0xe3, 0x3d,\n",
            "  0x19, 0xaf, 0x85, 0x3e, 0xac, 0x53, 0xd5, 0x3f, 0xe4, 0x4a, 0xc7, 0x3f,\n",
            "  0x1c, 0xcd, 0x4d, 0x3e, 0xcc, 0x97, 0x2b, 0x3a, 0xcc, 0x38, 0xa3, 0x3f,\n",
            "  0xbc, 0x6d, 0xd3, 0x3d, 0x49, 0xde, 0xd7, 0x3e, 0xdf, 0x87, 0x1a, 0x3f,\n",
            "  0xb9, 0x51, 0xaa, 0x3f, 0xa1, 0xfa, 0x0b, 0x3e, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x55, 0x25, 0x92, 0xbe, 0x56, 0xc7, 0xf2, 0xbe, 0x44, 0xc0, 0xee, 0xbf,\n",
            "  0xd6, 0x97, 0xcc, 0xbf, 0x80, 0x02, 0x64, 0xbe, 0x1d, 0x11, 0x45, 0xbe,\n",
            "  0xc7, 0x61, 0xa7, 0xbf, 0x75, 0xb6, 0x8d, 0xbe, 0x30, 0xa3, 0x32, 0xbe,\n",
            "  0xf0, 0x98, 0xfc, 0xbe, 0x5b, 0xf5, 0xa8, 0xbf, 0xbb, 0x39, 0x8a, 0xbe,\n",
            "  0x1e, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x5f, 0x34, 0x36, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64,\n",
            "  0x5f, 0x34, 0x36, 0x2f, 0x43, 0x6f, 0x6e, 0x76, 0x32, 0x44, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x5a, 0xfe, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x70, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00,\n",
            "  0x44, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x4c, 0xfe, 0xff, 0xff,\n",
            "  0x30, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x05, 0xf3, 0x7b, 0x3c, 0x01, 0x00, 0x00, 0x00, 0x84, 0x88, 0xb4, 0x3f,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x1f, 0xfb, 0xf9, 0xbf, 0x1d, 0x00, 0x00, 0x00,\n",
            "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x34,\n",
            "  0x36, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x35, 0x34, 0x2f, 0x4d,\n",
            "  0x61, 0x74, 0x4d, 0x75, 0x6c, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x0a, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0xde, 0xfe, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x02, 0x38, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x34, 0xff, 0xff, 0xff,\n",
            "  0x1e, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x5f, 0x34, 0x36, 0x2f, 0x66, 0x6c, 0x61, 0x74, 0x74, 0x65,\n",
            "  0x6e, 0x5f, 0x34, 0x35, 0x2f, 0x43, 0x6f, 0x6e, 0x73, 0x74, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x26, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x02, 0x74, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x38, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x0c, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x96, 0x82, 0x38, 0x3a, 0x2d, 0x00, 0x00, 0x00,\n",
            "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x34,\n",
            "  0x36, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x35, 0x34, 0x2f, 0x42,\n",
            "  0x69, 0x61, 0x73, 0x41, 0x64, 0x64, 0x2f, 0x52, 0x65, 0x61, 0x64, 0x56,\n",
            "  0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x4f, 0x70, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0xaa, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x02, 0x44, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x04, 0x00, 0x04, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x26, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
            "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x34, 0x36, 0x2f, 0x72, 0x65,\n",
            "  0x73, 0x68, 0x61, 0x70, 0x65, 0x5f, 0x31, 0x39, 0x2f, 0x52, 0x65, 0x73,\n",
            "  0x68, 0x61, 0x70, 0x65, 0x2f, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00,\n",
            "  0x18, 0x00, 0x08, 0x00, 0x07, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00,\n",
            "  0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09, 0x70, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x4c, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x14, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x2c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x80, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x81, 0x80, 0x80, 0x3b, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x3f,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x34, 0x36, 0x5f, 0x69, 0x6e,\n",
            "  0x70, 0x75, 0x74, 0x5f, 0x69, 0x6e, 0x74, 0x38, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
            "  0x1c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00,\n",
            "  0x80, 0x00, 0x00, 0x00, 0x64, 0x00, 0x00, 0x00, 0x50, 0x00, 0x00, 0x00,\n",
            "  0x38, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0xbe, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x06,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x07, 0x00,\n",
            "  0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x72, 0xc2, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x19, 0x02, 0x00, 0x00, 0x00, 0xe6, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00,\n",
            "  0x06, 0x00, 0x05, 0x00, 0x06, 0x00, 0x00, 0x00, 0x00, 0x16, 0x0a, 0x00,\n",
            "  0x0e, 0x00, 0x07, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x11, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0a, 0x00,\n",
            "  0x0c, 0x00, 0x07, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x03, 0x03, 0x00, 0x00, 0x00\n",
            "};\n",
            "unsigned int MNIST_full_quanitization_tflite_len = 3824;\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvBIhOTI2u1J",
        "colab_type": "text"
      },
      "source": [
        "This file is downloadable from the left hand menu of colab. Although this file is too large to be used as a model on a microcontroller. We will have to do some more optimizations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw7zP9zP80xP",
        "colab_type": "text"
      },
      "source": [
        "Pruning is where unncessart values in weight tensors are removed, thus reducing the number of parameters needed to store the model. This is done by further training the model while intermittently running pruning code that removes unnecessary connections between the layers of the neuran network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rah2i039XJg",
        "colab_type": "code",
        "outputId": "fb79bd6e-1ec6-4584-991d-9d7799d579f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        }
      },
      "source": [
        "!pip install -q tensorflow-model-optimization\n",
        "\n",
        "import numpy as np \n",
        "import os\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "end_step = np.ceil(1.0 * images_train.shape[0] / batch_size).astype(np.int32) * epochs\n",
        "print(end_step)\n",
        "\n",
        "pruning_params = {\n",
        "    'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.5,\n",
        "                                                 final_sparsity=0.9,\n",
        "                                                 begin_step=0,\n",
        "                                                 end_step=end_step,\n",
        "                                                 frequency=100\n",
        "                                                 )\n",
        "}\n",
        "\n",
        "new_pruned_model = sparsity.prune_low_magnitude(best_model, **pruning_params)\n",
        "new_pruned_model.summary()\n",
        "\n",
        "new_pruned_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "callbacks = [sparsity.UpdatePruningStep(),sparsity.PruningSummaries(log_dir=os.path.abspath(os.getcwd()), profile_batch=0)]\n",
        "\n",
        "new_pruned_model.fit(images_train, labels_train,\n",
        "                     batch_size=batch_size,\n",
        "                     epochs=epochs,\n",
        "                     verbose=1,\n",
        "                     callbacks=callbacks)\n",
        "\n",
        "score = new_pruned_model.evaluate(images_test, labels_test, verbose=0)\n",
        "print(\"Test loss: {}\".format(score[0]))\n",
        "print(\"Test accuracy: {}\".format(score[1]))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_conv2d_4 (None, 13, 13, 12)        230       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 4, 4, 12)          1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_reshape_ (None, 16, 12, 1)         1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 5, 4, 1)           1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten_ (None, 20)                1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_54 (None, 10)                412       \n",
            "=================================================================\n",
            "Total params: 646\n",
            "Trainable params: 330\n",
            "Non-trainable params: 316\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.6838 - accuracy: 0.7764\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.6144 - accuracy: 0.8001\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.7118 - accuracy: 0.7650\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.8540 - accuracy: 0.7215\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.9968 - accuracy: 0.6712\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 1.1185 - accuracy: 0.6259\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 1.1781 - accuracy: 0.6078\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 1.2891 - accuracy: 0.5413\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 1.3294 - accuracy: 0.5170\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 1.3231 - accuracy: 0.5181\n",
            "Test loss: 1.304140329360962\n",
            "Test accuracy: 0.527999997138977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9ctnEnjAzKu",
        "colab_type": "text"
      },
      "source": [
        "Now we can export the pruned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6oh6ZXXA1BF",
        "colab_type": "code",
        "outputId": "75db7ee8-b1ad-4a1e-eb10-4cffec9b449c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "new_pruned_model.summary()\n",
        "best_model_pruned = sparsity.strip_pruning(new_pruned_model)\n",
        "best_model_pruned.summary()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_conv2d_4 (None, 13, 13, 12)        230       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 4, 4, 12)          1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_reshape_ (None, 16, 12, 1)         1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 5, 4, 1)           1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten_ (None, 20)                1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_54 (None, 10)                412       \n",
            "=================================================================\n",
            "Total params: 646\n",
            "Trainable params: 330\n",
            "Non-trainable params: 316\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_46 (Conv2D)           (None, 13, 13, 12)        120       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 4, 4, 12)          0         \n",
            "_________________________________________________________________\n",
            "reshape_19 (Reshape)         (None, 16, 12, 1)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 5, 4, 1)           0         \n",
            "_________________________________________________________________\n",
            "flatten_45 (Flatten)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 330\n",
            "Trainable params: 330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSzcstilCDGL",
        "colab_type": "text"
      },
      "source": [
        "We can compare each pruned weight against zero to see how many weights were pruned out of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKhsXQz6CKCG",
        "colab_type": "code",
        "outputId": "aa2b981b-fca7-4e38-cda9-15c11c1e9c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "for i, w in enumerate(best_model_pruned.get_weights()):\n",
        "    print(\"{} -- Total:{}, Zeros: {:.2f}%\".format(\n",
        "        model.weights[i].name, w.size, np.sum(w == 0) / w.size * 100 ))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2d_44/kernel:0 -- Total:108, Zeros: 89.81%\n",
            "conv2d_44/bias:0 -- Total:12, Zeros: 0.00%\n",
            "dense_51/kernel:0 -- Total:200, Zeros: 90.00%\n",
            "dense_51/bias:0 -- Total:10, Zeros: 0.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtYoMRRnChQh",
        "colab_type": "text"
      },
      "source": [
        "Same as before we can quantize the model, convert and save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkFxO3jwCrF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(best_model_pruned)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"MNIST_pruned.tflite\", \"wb\").write(tflite_model)\n",
        "!xxd -i MNIST_pruned.tflite > MNIST_pruned.cc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKmWVr-UDCLM",
        "colab_type": "text"
      },
      "source": [
        "Puning saved us"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HWDND29DD3s",
        "colab_type": "code",
        "outputId": "b81d66ae-b565-4cec-b2e9-46d17b384982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Quanized file size difference is: {} bytes\".format(os.path.getsize(\"MNIST_model_no_optimizations.tflite\") - os.path.getsize(\"MNIST_full_quanitization.tflite\")))\n",
        "print(\"Pruned file size difference is: {} bytes\".format(os.path.getsize(\"MNIST_full_quanitization.tflite\") - os.path.getsize(\"MNIST_pruned.tflite\")))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quanized file size difference is: -504 bytes\n",
            "Pruned file size difference is: 0 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqGkaLQ3rfvI",
        "colab_type": "text"
      },
      "source": [
        "As the generated models are so large we need to make sure they are stored in the .rodata segment. To do so the model must be prefixed extern const such that it does not land in the .data segment and kill our ram. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fsVhonWuvV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sed -i '1s/^/extern const /' MNIST_full_quanitization.cc\n",
        "!sed -i '$s/^/extern const /' MNIST_full_quanitization.cc"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}