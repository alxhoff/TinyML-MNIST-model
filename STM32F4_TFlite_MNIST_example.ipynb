{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STM32F4 TFlite MNIST example",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4zUI9FmqnUm1jkL3azx+O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alxhoff/TinyML-MNIST-model/blob/master/STM32F4_TFlite_MNIST_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_q-FH0dgMQq",
        "colab_type": "text"
      },
      "source": [
        "This example will perform character recognition through user input into the touch screen of an STM3240G-Evaluation board using the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcNx6RbVg3cc",
        "colab_type": "code",
        "outputId": "556843ef-dbf4-44d8-d4de-dd23d508e40c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "!apt-get install -y xxd\n",
        "\n",
        "! pip uninstall -y tensorflow\n",
        "! pip install -q tf-nightly\n",
        "! pip install -q tensorflow-model-optimization\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "(images_train, labels_train), (images_test, labels_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 63%\r\rReading package lists... 63%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 71%\r\rReading package lists... 71%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "xxd is already the newest version (2:8.0.1453-1ubuntu1.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y2hcinVg4Ws",
        "colab_type": "text"
      },
      "source": [
        "Importing Tensorflow allows you to use its API to load the MNIST dataset. It should be noted that we need to use TF version <1.14 as this version includes the fully connected operation version 3 which is incompatible with the micro interpreters version 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnCKuVlVjRhX",
        "colab_type": "code",
        "outputId": "562812ae-aacb-4677-f1b3-fd06add9daf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "test_index = 12345\n",
        "print(labels_train[test_index])\n",
        "plt.imshow(images_train[test_index], cmap='Greys')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f224f7547b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-76bBO2rlABd",
        "colab_type": "text"
      },
      "source": [
        "The input of the neural network needs to know the input shape that it is going to be fed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWwrc29FlEgQ",
        "colab_type": "code",
        "outputId": "fc0bc888-f0dc-41a6-f085-bf7df337f29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_shape = images_train.shape\n",
        "print(\"{} images, each with shape of {} pixels x {} pixels\".format(input_shape[0], input_shape[1], input_shape[2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 images, each with shape of 28 pixels x 28 pixels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn-3cvuymAWT",
        "colab_type": "text"
      },
      "source": [
        "The input shape for the model must be reshaped to 4D as the current shape does not show that each pixel is a 1D array where only the greyscale value (0-255) is stored. The input tensor's shape will be 3D as it will take a single-channel image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOZnWmzUmTuI",
        "colab_type": "code",
        "outputId": "2412eb06-ba8e-4213-e16e-67346be00707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "images_train = images_train.reshape(images_train.shape[0], images_train.shape[1], images_train.shape[2], 1)\n",
        "images_test = images_test.reshape(images_test.shape[0], images_test.shape[1], images_test.shape[2], 1)\n",
        "input_tensor_shape = (images_test.shape[1], images_test.shape[2], 1)\n",
        "print(\"Input shape: {}\".format(input_shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: (60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjPMYztkm0tg",
        "colab_type": "text"
      },
      "source": [
        "The greyscale values stores in the images' pixels are 8 bit values and need to be normalized into floats between 0-1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adD13BYinHlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_train = images_train.astype('float32')\n",
        "images_test = images_test.astype('float32')\n",
        "images_train /= 255\n",
        "images_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3oXnIHunXvs",
        "colab_type": "text"
      },
      "source": [
        "Now the convolutional NN that we will use to classify the input images taken from the touch screen will have the following layer structure\n",
        "\n",
        "1. Conv2D\n",
        "2. MaxPooling2D\n",
        "3. Flatten\n",
        "4. Dense\n",
        "5. Dropout\n",
        "11. Dense\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-2aWbOirRCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(28, kernel_size=(3,3), input_shape=input_tensor_shape))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(keras.layers.Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model.add(keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "model2 = keras.Sequential()\n",
        "\n",
        "model2.add(keras.layers.Conv2D(12, kernel_size=(3,3), input_shape=input_tensor_shape))\n",
        "model2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(keras.layers.Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model2.add(keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "model3 = keras.Sequential()\n",
        "\n",
        "model3.add(keras.layers.Conv2D(12, kernel_size=(3,3), strides=(2,2), input_shape=input_tensor_shape))\n",
        "model3.add(keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "model3.add(keras.layers.Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model3.add(keras.layers.Reshape((192,1)))\n",
        "model3.add(keras.layers.MaxPooling1D(pool_size=6, padding='valid', data_format='channels_last'))\n",
        "model3.add(keras.layers.Flatten())\n",
        "model3.add(keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "model4 = keras.Sequential()\n",
        "\n",
        "model4.add(keras.layers.Conv2D(12, kernel_size=(3,3), strides=(2,2), input_shape=input_tensor_shape))\n",
        "model4.add(keras.layers.Reshape( (13, 13, 12, 1)))\n",
        "model4.add(keras.layers.MaxPooling3D(pool_size=(6, 3,3)))\n",
        "model4.add(keras.layers.Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model4.add(keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "model5 = keras.Sequential()\n",
        "\n",
        "model5.add(keras.layers.Conv2D(12, kernel_size=(3,3), strides=(2,2), input_shape=input_tensor_shape))\n",
        "model5.add(keras.layers.Reshape( (169, 12, 1)))\n",
        "model5.add(keras.layers.MaxPooling2D(pool_size=(18, 3)))\n",
        "# model5.add(keras.layers.MaxPooling2D(pool_size=(12, 12), strides=(9,2)))\n",
        "model5.add(keras.layers.Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model5.add(keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "quantized_model5 = quantize_model(model5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5CLXe63rRPf",
        "colab_type": "text"
      },
      "source": [
        "The Conv2D layer extracts features from the input image using filters that slide across the input image. In this case we will use 28 different filters to extract a large number of unique features that will then be used to classify each image in the later layers. Thus the output of this layer will have the shape (28, 28, 1, 28)\n",
        "\n",
        "MaxPooling2D is used to reduce the output size of the convolutional layer by reducing each 2 x 2 unique chunk of the output down in to a singular value, this reducing the output's size by a factor of 4. This will reduce our (28, 28, 1, 28) tensor down to a (7, 7, 1, 28) tensor.\n",
        "\n",
        "The Flatten layer then takes this 2D array (our image) and shapes it into a single dimension (1372).\n",
        "\n",
        "The following Dense layer reduces the input 1372 values down into 128 classes, taking the first steps in classifying the image into on of the 10 output classes (0-9). This is done using the relu activation function.\n",
        "\n",
        "The Dropout layer sets 20% of the tensor's values to 0 so as to reduce overfitting.\n",
        "\n",
        "Finally the last Dense layer reduces the output value down to the 10 classes, each representing a digit between 0 and 9. This is done using the softmax activation function which makes the outputs a set of probabilities summing to 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrG75fkHxdkN",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXWfgL0LxS3o",
        "colab_type": "code",
        "outputId": "37c7131a-17f8-49fa-9164-592d70a796f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model4.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model5.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "quantized_model5.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 10\n",
        "\n",
        "print(\"Model 1\")\n",
        "history = model.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "model.summary()\n",
        "\n",
        "print(\"Model 2\")\n",
        "history2 = model2.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "model2.summary()\n",
        "\n",
        "print(\"Model 3\")\n",
        "history3 = model3.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "model3.summary()\n",
        "\n",
        "print(\"Model 4\")\n",
        "history4 = model4.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "model4.summary()\n",
        "\n",
        "print(\"Model 5\")\n",
        "history5 = model5.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "model5.summary()\n",
        "\n",
        "print(\"Model 5 Quantized\")\n",
        "history5_q = quantized_model5.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "quantized_model5.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.2638 - accuracy: 0.9215\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.1042 - accuracy: 0.9682\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.0680 - accuracy: 0.9799\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.0509 - accuracy: 0.9843\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.0399 - accuracy: 0.9873\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.0329 - accuracy: 0.9893\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.0260 - accuracy: 0.9913\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.0229 - accuracy: 0.9923\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.0196 - accuracy: 0.9934\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.0161 - accuracy: 0.9947\n",
            "Model: \"sequential_256\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_266 (Conv2D)          (None, 26, 26, 28)        280       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_221 (MaxPoolin (None, 13, 13, 28)        0         \n",
            "_________________________________________________________________\n",
            "flatten_296 (Flatten)        (None, 4732)              0         \n",
            "_________________________________________________________________\n",
            "dense_297 (Dense)            (None, 128)               605824    \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_298 (Dense)            (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 607,394\n",
            "Trainable params: 607,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model 2\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.4159 - accuracy: 0.8870\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.2126 - accuracy: 0.9388\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.1656 - accuracy: 0.9531\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.1360 - accuracy: 0.9622\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.1171 - accuracy: 0.9665\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.1034 - accuracy: 0.9710\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0930 - accuracy: 0.9729\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0839 - accuracy: 0.9760\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0773 - accuracy: 0.9776\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0727 - accuracy: 0.9785\n",
            "Model: \"sequential_257\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_267 (Conv2D)          (None, 26, 26, 12)        120       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_222 (MaxPoolin (None, 13, 13, 12)        0         \n",
            "_________________________________________________________________\n",
            "flatten_297 (Flatten)        (None, 2028)              0         \n",
            "_________________________________________________________________\n",
            "dense_299 (Dense)            (None, 10)                20290     \n",
            "=================================================================\n",
            "Total params: 20,410\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model 3\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 1.5435 - accuracy: 0.5024\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.7588 - accuracy: 0.7696\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.5826 - accuracy: 0.8209\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.5023 - accuracy: 0.8442\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.4585 - accuracy: 0.8561\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.4307 - accuracy: 0.8642\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.4111 - accuracy: 0.8694\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.3958 - accuracy: 0.8736\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.3833 - accuracy: 0.8765\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.3742 - accuracy: 0.8788\n",
            "Model: \"sequential_258\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_268 (Conv2D)          (None, 13, 13, 12)        120       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_223 (MaxPoolin (None, 4, 4, 12)          0         \n",
            "_________________________________________________________________\n",
            "flatten_298 (Flatten)        (None, 192)               0         \n",
            "_________________________________________________________________\n",
            "reshape_122 (Reshape)        (None, 192, 1)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_52 (MaxPooling (None, 32, 1)             0         \n",
            "_________________________________________________________________\n",
            "flatten_299 (Flatten)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_300 (Dense)            (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 450\n",
            "Trainable params: 450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model 4\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 1.7729 - accuracy: 0.3988\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 1.2304 - accuracy: 0.6035\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 1.0050 - accuracy: 0.6882\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.8558 - accuracy: 0.7359\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.7549 - accuracy: 0.7667\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.6848 - accuracy: 0.7858\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.6361 - accuracy: 0.8009\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.6003 - accuracy: 0.8106\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.5712 - accuracy: 0.8194\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.5485 - accuracy: 0.8255\n",
            "Model: \"sequential_259\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_269 (Conv2D)          (None, 13, 13, 12)        120       \n",
            "_________________________________________________________________\n",
            "reshape_123 (Reshape)        (None, 13, 13, 12, 1)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_50 (MaxPooling (None, 2, 4, 4, 1)        0         \n",
            "_________________________________________________________________\n",
            "flatten_300 (Flatten)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_301 (Dense)            (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 450\n",
            "Trainable params: 450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model 5\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 1.7704 - accuracy: 0.4210\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 1.0238 - accuracy: 0.6891\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.7883 - accuracy: 0.7544\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.7060 - accuracy: 0.7757\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.6604 - accuracy: 0.7885\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.6170 - accuracy: 0.8024\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.5879 - accuracy: 0.8101\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.5634 - accuracy: 0.8193\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.5412 - accuracy: 0.8264\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.5225 - accuracy: 0.8332\n",
            "Model: \"sequential_260\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_270 (Conv2D)          (None, 13, 13, 12)        120       \n",
            "_________________________________________________________________\n",
            "reshape_124 (Reshape)        (None, 169, 12, 1)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_224 (MaxPoolin (None, 9, 4, 1)           0         \n",
            "_________________________________________________________________\n",
            "flatten_301 (Flatten)        (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_302 (Dense)            (None, 10)                370       \n",
            "=================================================================\n",
            "Total params: 490\n",
            "Trainable params: 490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model 5 Quantized\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 1.7809 - accuracy: 0.4169\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 1.0164 - accuracy: 0.6962\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.7794 - accuracy: 0.7586\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.6930 - accuracy: 0.7799\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.6487 - accuracy: 0.7919\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.6204 - accuracy: 0.8007\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.5992 - accuracy: 0.8077\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.5793 - accuracy: 0.8134\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.5612 - accuracy: 0.8205\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.5440 - accuracy: 0.8258\n",
            "Model: \"sequential_260\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "quantize_layer_33 (QuantizeL (None, 28, 28, 1)         3         \n",
            "_________________________________________________________________\n",
            "quant_conv2d_270 (QuantizeWr (None, 13, 13, 12)        147       \n",
            "_________________________________________________________________\n",
            "quant_reshape_124 (QuantizeW (None, 169, 12, 1)        1         \n",
            "_________________________________________________________________\n",
            "quant_max_pooling2d_224 (Qua (None, 9, 4, 1)           1         \n",
            "_________________________________________________________________\n",
            "quant_flatten_301 (QuantizeW (None, 36)                1         \n",
            "_________________________________________________________________\n",
            "quant_dense_302 (QuantizeWra (None, 10)                375       \n",
            "=================================================================\n",
            "Total params: 528\n",
            "Trainable params: 490\n",
            "Non-trainable params: 38\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNtcEcKuxgYb",
        "colab_type": "text"
      },
      "source": [
        "Now we can evaluate our trained model using the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4zrA9hNxkAC",
        "colab_type": "code",
        "outputId": "a609f283-74a6-4406-d845-81212d411b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "res = model.evaluate(images_test, labels_test)\n",
        "print(\"Model1 has an accuracy of {0:.2f}%\".format(res[1] * 100))\n",
        "\n",
        "res = model2.evaluate(images_test, labels_test)\n",
        "print(\"Model2 has an accuracy of {0:.2f}%\".format(res[1] * 100))\n",
        "\n",
        "res = model3.evaluate(images_test, labels_test)\n",
        "print(\"Model3 has an accuracy of {0:.2f}%\".format(res[1] * 100))\n",
        "\n",
        "res = model4.evaluate(images_test, labels_test)\n",
        "print(\"Model4 has an accuracy of {0:.2f}%\".format(res[1] * 100))\n",
        "\n",
        "res = model5.evaluate(images_test, labels_test)\n",
        "print(\"Model5 has an accuracy of {0:.2f}%\".format(res[1] * 100))\n",
        "\n",
        "res = quantized_model5.evaluate(images_test, labels_test)\n",
        "print(\"Quantized model5 has an accuracy of {0:.2f}%\".format(res[1] * 100))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9870\n",
            "Model1 has an accuracy of 98.70%\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0834 - accuracy: 0.9748\n",
            "Model2 has an accuracy of 97.48%\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3506 - accuracy: 0.8904\n",
            "Model3 has an accuracy of 89.04%\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5109 - accuracy: 0.8371\n",
            "Model4 has an accuracy of 83.71%\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4940 - accuracy: 0.8440\n",
            "Model5 has an accuracy of 84.40%\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5195 - accuracy: 0.8361\n",
            "Quantized model5 has an accuracy of 83.61%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeIhxRzT3w7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = quantized_model5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytu4OjmCzMIT",
        "colab_type": "text"
      },
      "source": [
        "Now we will need to convert and save our model into a downloadable file that will be appropriate for a microcontroller. This is done using the TensorFlow Lite Converter. The `TFLITE_BUILTINS` option tells the converter to only use TensorFlow Lite built in operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ8FDCOczYMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"MNIST_model_no_optimizations.tflite\", \"wb\").write(tflite_model)\n",
        "!xxd -i MNIST_model_no_optimizations.tflite > MNIST_model_no_optimizations.cc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it6Eoe3x1B0U",
        "colab_type": "text"
      },
      "source": [
        "Now we will be running this model on a constrained device and as such we will need to perform quantization and optimizations to reduce the size of the model. The optimizations that TensorFlow offers are detailed [here](https://www.tensorflow.org/lite/performance/model_optimization). Also see [here](https://www.tensorflow.org/model_optimization/guide/quantization/training) for more information on quanitazation aware training and [here](https://www.tensorflow.org/lite/performance/post_training_quantization) for information on post-training quantization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW9_WVtz1K5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"MNIST_optimized_for_size.tflite\", \"wb\").write(tflite_model)\n",
        "!xxd -i MNIST_optimized_for_size.tflite > MNIST_optimized_for_size.cc\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"MNIST_default_optimizations.tflite\", \"wb\").write(tflite_model)\n",
        "!xxd -i MNIST_default_optimizations.tflite > MNIST_default_optimizations.cc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ysFrDZq13Zx",
        "colab_type": "text"
      },
      "source": [
        "These optimizations reduced the file size significantly but we can do better. Enforcing full integer quantization for all operations as well as ensuring all model math is quantized to 8-bit. Doing so requires a representative dataset that can be used to evaluate optimizations made by the converter. The representative dataset must be a python iterator.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7WgyAFXCvk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "best_model = model5\n",
        "\n",
        "def representative_dataset_gen():\n",
        "  for image in images_test:\n",
        "    array = np.array(image)\n",
        "    array = np.expand_dims(array, axis = 0)\n",
        "    yield ([array])\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"MNIST_full_quanitization.tflite\", \"wb\").write(tflite_model)\n",
        "!xxd -i MNIST_full_quanitization.tflite > MNIST_full_quanitization.cc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JBLhgQ-2PXr",
        "colab_type": "text"
      },
      "source": [
        "This file needs to now be included in our microcontroller project and as such must be in a form that is easily usable on a device without a file system. xxd can be used to convert the model into a C source file where the model is stored as a byte array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Encu0Li72cmB",
        "colab_type": "code",
        "outputId": "7cdfed22-15ac-4e1e-a0dc-bd8fd4569229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!xxd -i MNIST_full_quanitization.tflite > MNIST_full_quanitization.cc\n",
        "!cat MNIST_full_quanitization.cc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unsigned char MNIST_full_quanitization_tflite[] = {\n",
            "  0x24, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x12, 0x00, 0x1c, 0x00, 0x04, 0x00,\n",
            "  0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x00,\n",
            "  0x12, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x44, 0x0f, 0x00, 0x00,\n",
            "  0xe4, 0x03, 0x00, 0x00, 0xcc, 0x03, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x0c, 0x00, 0x04, 0x00, 0x08, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00,\n",
            "  0x6d, 0x69, 0x6e, 0x5f, 0x72, 0x75, 0x6e, 0x74, 0x69, 0x6d, 0x65, 0x5f,\n",
            "  0x76, 0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e, 0x00, 0x0f, 0x00, 0x00, 0x00,\n",
            "  0x84, 0x03, 0x00, 0x00, 0x70, 0x03, 0x00, 0x00, 0x34, 0x03, 0x00, 0x00,\n",
            "  0x10, 0x03, 0x00, 0x00, 0xec, 0x02, 0x00, 0x00, 0x68, 0x01, 0x00, 0x00,\n",
            "  0xe4, 0x00, 0x00, 0x00, 0xa0, 0x00, 0x00, 0x00, 0x94, 0x00, 0x00, 0x00,\n",
            "  0x80, 0x00, 0x00, 0x00, 0x6c, 0x00, 0x00, 0x00, 0x58, 0x00, 0x00, 0x00,\n",
            "  0x44, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x06, 0xfc, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x31, 0x2e, 0x35, 0x2e, 0x30, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0xd0, 0xf2, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xe0, 0xf2, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0xf0, 0xf2, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0xf3, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x10, 0xf3, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x20, 0xf3, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x86, 0xfc, 0xff, 0xff,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00, 0x5f, 0x27, 0x00, 0x00,\n",
            "  0xa4, 0xe1, 0xff, 0xff, 0x0c, 0xf1, 0xff, 0xff, 0xde, 0x8a, 0xff, 0xff,\n",
            "  0x7f, 0xaa, 0xff, 0xff, 0x9c, 0xf8, 0xff, 0xff, 0xe0, 0xe1, 0xff, 0xff,\n",
            "  0xdc, 0xe5, 0xff, 0xff, 0xf2, 0x26, 0xff, 0xff, 0xeb, 0xee, 0xff, 0xff,\n",
            "  0x69, 0x17, 0x00, 0x00, 0x70, 0xf3, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
            "  0xc6, 0xfc, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x6c, 0x00, 0x00, 0x00,\n",
            "  0xfb, 0x81, 0xb1, 0x32, 0x39, 0x54, 0x41, 0x04, 0x4f, 0x81, 0xfb, 0x8f,\n",
            "  0xb7, 0x25, 0xc1, 0xed, 0xe2, 0x90, 0x60, 0x4a, 0x7f, 0x1a, 0xf1, 0x33,\n",
            "  0x85, 0x97, 0xaa, 0x59, 0xc3, 0xa8, 0xd9, 0xc7, 0xd0, 0x35, 0x81, 0xfb,\n",
            "  0xcf, 0xc7, 0x0c, 0xc5, 0xf2, 0xce, 0x0f, 0x81, 0x1b, 0x81, 0xb9, 0x18,\n",
            "  0xb2, 0x0e, 0x3e, 0xdb, 0x47, 0x41, 0x2b, 0x65, 0x59, 0xcc, 0x2f, 0x41,\n",
            "  0xa9, 0x55, 0x7f, 0x74, 0x40, 0xd3, 0x3e, 0x18, 0x9b, 0x5c, 0x7f, 0x42,\n",
            "  0x0b, 0x10, 0x2d, 0x81, 0xa5, 0xd7, 0xea, 0x1a, 0x8c, 0xde, 0xa7, 0x9f,\n",
            "  0xf2, 0xcc, 0x1e, 0x23, 0x81, 0xf8, 0x09, 0x02, 0x78, 0x7f, 0x34, 0x64,\n",
            "  0x6b, 0x16, 0x32, 0xb3, 0x62, 0x81, 0x76, 0xdb, 0xa1, 0x21, 0xbd, 0x34,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x46, 0xfd, 0xff, 0xff,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x68, 0x01, 0x00, 0x00, 0x08, 0xef, 0xfc, 0xf2,\n",
            "  0xeb, 0x08, 0xf8, 0x0a, 0x01, 0x09, 0x10, 0x10, 0x28, 0x27, 0x07, 0x06,\n",
            "  0xf2, 0x26, 0xfc, 0xf3, 0xae, 0x39, 0x11, 0xf0, 0xbf, 0x08, 0xdf, 0xed,\n",
            "  0x2f, 0xe9, 0x00, 0xf4, 0x0b, 0x9b, 0xf2, 0x17, 0xf1, 0x0b, 0xf4, 0x0e,\n",
            "  0xaa, 0x21, 0x0b, 0xf8, 0x95, 0x12, 0x2f, 0x1a, 0x94, 0xf8, 0xfb, 0x04,\n",
            "  0xb4, 0x15, 0x0b, 0x00, 0xb5, 0x12, 0x10, 0x0a, 0x99, 0x28, 0x1d, 0x01,\n",
            "  0xc7, 0x20, 0x29, 0x16, 0xef, 0x22, 0x0b, 0xe0, 0x09, 0x07, 0xfb, 0x0d,\n",
            "  0x2e, 0xe9, 0x03, 0x15, 0x19, 0xd6, 0x25, 0x0c, 0x25, 0xbe, 0xf9, 0xe3,\n",
            "  0xc5, 0x24, 0xd8, 0x01, 0xf3, 0x2c, 0xc7, 0x02, 0x1b, 0x13, 0x09, 0x16,\n",
            "  0x27, 0x0a, 0xfe, 0xf8, 0x04, 0xec, 0xdf, 0xed, 0x06, 0x0b, 0xe3, 0xf6,\n",
            "  0x27, 0xef, 0x0f, 0x06, 0x1c, 0xc6, 0x25, 0x08, 0x27, 0xde, 0xe3, 0xf4,\n",
            "  0x2b, 0xdd, 0x1b, 0x19, 0x26, 0xc5, 0xff, 0xea, 0x09, 0xe9, 0xde, 0xe5,\n",
            "  0x24, 0xff, 0xf3, 0x0f, 0x11, 0x18, 0xec, 0x12, 0xdf, 0x1f, 0xf8, 0xde,\n",
            "  0xb1, 0x1e, 0xf8, 0xe7, 0x8a, 0x3c, 0x1b, 0xe6, 0x81, 0x21, 0xf0, 0xe6,\n",
            "  0xdf, 0x24, 0x06, 0xf9, 0x48, 0xe0, 0x15, 0x24, 0x31, 0xee, 0x17, 0x0a,\n",
            "  0xce, 0x13, 0x22, 0x08, 0xe1, 0x25, 0x12, 0xfe, 0xf1, 0x07, 0xcb, 0x09,\n",
            "  0x0e, 0x18, 0xca, 0xf8, 0x35, 0x0d, 0xc8, 0x07, 0x20, 0x0e, 0x22, 0x15,\n",
            "  0x1e, 0xc0, 0x06, 0xe5, 0x39, 0xc4, 0x0b, 0xe4, 0x09, 0xe5, 0xfa, 0xfa,\n",
            "  0x11, 0xf7, 0xe6, 0x07, 0x26, 0xf5, 0xdf, 0x19, 0xfa, 0x1a, 0x09, 0x11,\n",
            "  0xf6, 0x4b, 0x07, 0x2b, 0xe7, 0x3f, 0xc6, 0x02, 0xcc, 0x33, 0xd9, 0x0d,\n",
            "  0xec, 0x0f, 0xef, 0x02, 0x15, 0x13, 0x18, 0xed, 0xf2, 0x02, 0xf7, 0xfe,\n",
            "  0xf8, 0xe9, 0xe9, 0x0d, 0xf8, 0xab, 0xfd, 0xcb, 0xe8, 0xcd, 0xfd, 0xe8,\n",
            "  0xdd, 0xe0, 0xf8, 0xd9, 0xf2, 0xd3, 0xf9, 0xe5, 0x22, 0xb7, 0xf9, 0x14,\n",
            "  0xe2, 0x13, 0x14, 0xe2, 0xd5, 0x2f, 0xed, 0xff, 0xcf, 0x21, 0x15, 0x1e,\n",
            "  0xed, 0x16, 0x04, 0x04, 0xdf, 0x40, 0x3d, 0x28, 0xfd, 0xe4, 0xf7, 0xf0,\n",
            "  0x07, 0x13, 0xe5, 0x0a, 0x0f, 0x12, 0x01, 0xf4, 0x07, 0xeb, 0x01, 0xe5,\n",
            "  0x31, 0xe4, 0xf0, 0x06, 0x13, 0xe9, 0x0a, 0x17, 0x15, 0x1d, 0x00, 0xfc,\n",
            "  0xcb, 0xf6, 0x15, 0xe1, 0x1d, 0xe3, 0x0a, 0x1c, 0x07, 0xec, 0xfa, 0xdc,\n",
            "  0xd8, 0xe9, 0x1d, 0xdc, 0x19, 0x09, 0xe5, 0x0e, 0x0d, 0x2f, 0xf8, 0xde,\n",
            "  0xe5, 0xee, 0x0d, 0x23, 0x0f, 0xd3, 0x04, 0x0a, 0x0d, 0x08, 0xee, 0xf4,\n",
            "  0xd9, 0x06, 0x09, 0xf8, 0xca, 0x33, 0x33, 0x11, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xc6, 0xfe, 0xff, 0xff,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0xa9, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0xe6, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0x24, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x06, 0xff, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00,\n",
            "  0xcc, 0xfd, 0xff, 0xff, 0x2c, 0x02, 0x00, 0x00, 0x35, 0x00, 0x00, 0x00,\n",
            "  0x69, 0x00, 0x00, 0x00, 0x23, 0xff, 0xff, 0xff, 0x75, 0x03, 0x00, 0x00,\n",
            "  0x9b, 0xff, 0xff, 0xff, 0xd2, 0x00, 0x00, 0x00, 0xbe, 0xfd, 0xff, 0xff,\n",
            "  0x3b, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0xe0, 0xf5, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0xf0, 0xf5, 0xff, 0xff, 0x0f, 0x00, 0x00, 0x00, 0x4d, 0x4c, 0x49, 0x52,\n",
            "  0x20, 0x43, 0x6f, 0x6e, 0x76, 0x65, 0x72, 0x74, 0x65, 0x64, 0x2e, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00,\n",
            "  0x18, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00,\n",
            "  0x0e, 0x00, 0x00, 0x00, 0x1c, 0x02, 0x00, 0x00, 0x10, 0x02, 0x00, 0x00,\n",
            "  0x04, 0x02, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x6d, 0x61, 0x69, 0x6e, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x00, 0x00, 0xc8, 0x01, 0x00, 0x00, 0x70, 0x01, 0x00, 0x00,\n",
            "  0x38, 0x01, 0x00, 0x00, 0xe4, 0x00, 0x00, 0x00, 0xac, 0x00, 0x00, 0x00,\n",
            "  0x74, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x62, 0xfe, 0xff, 0xff, 0x06, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x5e, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x04, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00,\n",
            "  0x08, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x3f,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x0b, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x08, 0x00,\n",
            "  0x0c, 0x00, 0x10, 0x00, 0x07, 0x00, 0x14, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x08, 0x03, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xe8, 0xf6, 0xff, 0xff,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x0a, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0xfe, 0xfe, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x0e, 0x00, 0x1a, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00,\n",
            "  0x07, 0x00, 0x14, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x05,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x07, 0x00,\n",
            "  0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x01, 0x03, 0x00, 0x00, 0x00, 0x12, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x12, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x09, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x82, 0xff, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x0e, 0x00, 0x16, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0c, 0x00,\n",
            "  0x07, 0x00, 0x10, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,\n",
            "  0x30, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x0a, 0x00, 0x10, 0x00, 0x07, 0x00, 0x08, 0x00, 0x0c, 0x00,\n",
            "  0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00,\n",
            "  0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x10, 0x00, 0x04, 0x00,\n",
            "  0x08, 0x00, 0x0c, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x0d, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x94, 0x08, 0x00, 0x00,\n",
            "  0xf0, 0x07, 0x00, 0x00, 0x9c, 0x07, 0x00, 0x00, 0x44, 0x07, 0x00, 0x00,\n",
            "  0xc0, 0x06, 0x00, 0x00, 0x54, 0x05, 0x00, 0x00, 0x08, 0x04, 0x00, 0x00,\n",
            "  0x1c, 0x03, 0x00, 0x00, 0x88, 0x02, 0x00, 0x00, 0xec, 0x01, 0x00, 0x00,\n",
            "  0x60, 0x01, 0x00, 0x00, 0xd4, 0x00, 0x00, 0x00, 0x78, 0x00, 0x00, 0x00,\n",
            "  0x3c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xd8, 0xff, 0xff, 0xff,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x49, 0x64, 0x65, 0x6e, 0x74, 0x69, 0x74, 0x79, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x0c, 0x00, 0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x32,\n",
            "  0x37, 0x30, 0x5f, 0x69, 0x6e, 0x70, 0x75, 0x74, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
            "  0x1c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x22, 0xf8, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x44, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
            "  0x28, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xb4, 0xf8, 0xff, 0xff,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x80, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x80, 0x3b, 0x0d, 0x00, 0x00, 0x00, 0x49, 0x64, 0x65, 0x6e,\n",
            "  0x74, 0x69, 0x74, 0x79, 0x5f, 0x69, 0x6e, 0x74, 0x38, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x7a, 0xf8, 0xff, 0xff, 0x00, 0x00, 0x00, 0x09, 0x74, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x44, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x6c, 0xf8, 0xff, 0xff, 0x30, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x0f, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x36, 0x06, 0xfb, 0x3d, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x50, 0x5c, 0x41, 0x01, 0x00, 0x00, 0x00, 0x30, 0xe3, 0x8b, 0xc1,\n",
            "  0x20, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x5f, 0x32, 0x36, 0x30, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65,\n",
            "  0x5f, 0x33, 0x30, 0x32, 0x2f, 0x42, 0x69, 0x61, 0x73, 0x41, 0x64, 0x64,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x0a, 0x00, 0x00, 0x00, 0x02, 0xf9, 0xff, 0xff, 0x00, 0x00, 0x00, 0x09,\n",
            "  0x74, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x44, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0xf4, 0xf8, 0xff, 0xff, 0x30, 0x00, 0x00, 0x00,\n",
            "  0x24, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xf2, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xbb, 0x76, 0x50, 0x3d,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x07, 0x46, 0xe6, 0x40, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x81, 0x06, 0xb9, 0xc0, 0x22, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
            "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x32, 0x36, 0x30, 0x2f, 0x66,\n",
            "  0x6c, 0x61, 0x74, 0x74, 0x65, 0x6e, 0x5f, 0x33, 0x30, 0x31, 0x2f, 0x52,\n",
            "  0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x8a, 0xf9, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x7c, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x44, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x7c, 0xf9, 0xff, 0xff,\n",
            "  0x30, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xf2, 0xff, 0xff, 0xff,\n",
            "  0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0xbb, 0x76, 0x50, 0x3d, 0x01, 0x00, 0x00, 0x00, 0x07, 0x46, 0xe6, 0x40,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x81, 0x06, 0xb9, 0xc0, 0x28, 0x00, 0x00, 0x00,\n",
            "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x32,\n",
            "  0x36, 0x30, 0x2f, 0x6d, 0x61, 0x78, 0x5f, 0x70, 0x6f, 0x6f, 0x6c, 0x69,\n",
            "  0x6e, 0x67, 0x32, 0x64, 0x5f, 0x32, 0x32, 0x34, 0x2f, 0x4d, 0x61, 0x78,\n",
            "  0x50, 0x6f, 0x6f, 0x6c, 0x00, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x22, 0xfa, 0xff, 0xff, 0x00, 0x00, 0x00, 0x09,\n",
            "  0x74, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x44, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x14, 0xfa, 0xff, 0xff, 0x30, 0x00, 0x00, 0x00,\n",
            "  0x24, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xf2, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xbb, 0x76, 0x50, 0x3d,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x07, 0x46, 0xe6, 0x40, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x81, 0x06, 0xb9, 0xc0, 0x22, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
            "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x32, 0x36, 0x30, 0x2f, 0x72,\n",
            "  0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x5f, 0x31, 0x32, 0x34, 0x2f, 0x52,\n",
            "  0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xa9, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xb2, 0xfa, 0xff, 0xff, 0x00, 0x00, 0x00, 0x09,\n",
            "  0xcc, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0xa4, 0xfa, 0xff, 0xff, 0x2c, 0x00, 0x00, 0x00,\n",
            "  0x20, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xf2, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xbb, 0x76, 0x50, 0x3d, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x07, 0x46, 0xe6, 0x40, 0x01, 0x00, 0x00, 0x00, 0x81, 0x06, 0xb9, 0xc0,\n",
            "  0x7d, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x5f, 0x32, 0x36, 0x30, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32,\n",
            "  0x64, 0x5f, 0x32, 0x37, 0x30, 0x2f, 0x42, 0x69, 0x61, 0x73, 0x41, 0x64,\n",
            "  0x64, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c,\n",
            "  0x5f, 0x32, 0x36, 0x30, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f,\n",
            "  0x32, 0x37, 0x30, 0x2f, 0x43, 0x6f, 0x6e, 0x76, 0x32, 0x44, 0x3b, 0x73,\n",
            "  0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x32, 0x36,\n",
            "  0x30, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x32, 0x37, 0x30,\n",
            "  0x2f, 0x42, 0x69, 0x61, 0x73, 0x41, 0x64, 0x64, 0x2f, 0x52, 0x65, 0x61,\n",
            "  0x64, 0x56, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x4f, 0x70, 0x2f,\n",
            "  0x72, 0x65, 0x73, 0x6f, 0x75, 0x72, 0x63, 0x65, 0x31, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
            "  0x0d, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x9a, 0xfb, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x02, 0x38, 0x01, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00,\n",
            "  0xac, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x2c, 0xfc, 0xff, 0xff,\n",
            "  0x6c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0xdd, 0xce, 0xd6, 0x37, 0x03, 0xa9, 0xcd, 0x36,\n",
            "  0x08, 0x1f, 0x56, 0x38, 0x54, 0x6d, 0xdf, 0x36, 0x09, 0xed, 0x04, 0x37,\n",
            "  0x6b, 0x0a, 0x94, 0x38, 0x35, 0x36, 0x05, 0x38, 0xff, 0xea, 0x17, 0x38,\n",
            "  0x38, 0x06, 0x96, 0x36, 0xd0, 0xa2, 0xc7, 0x36, 0x01, 0x56, 0x41, 0x38,\n",
            "  0xe3, 0xb0, 0xe8, 0x36, 0x7c, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
            "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x32, 0x36, 0x30, 0x2f, 0x63,\n",
            "  0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x32, 0x37, 0x30, 0x2f, 0x42, 0x69,\n",
            "  0x61, 0x73, 0x41, 0x64, 0x64, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e,\n",
            "  0x74, 0x69, 0x61, 0x6c, 0x5f, 0x32, 0x36, 0x30, 0x2f, 0x63, 0x6f, 0x6e,\n",
            "  0x76, 0x32, 0x64, 0x5f, 0x32, 0x37, 0x30, 0x2f, 0x43, 0x6f, 0x6e, 0x76,\n",
            "  0x32, 0x44, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61,\n",
            "  0x6c, 0x5f, 0x32, 0x36, 0x30, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64,\n",
            "  0x5f, 0x32, 0x37, 0x30, 0x2f, 0x42, 0x69, 0x61, 0x73, 0x41, 0x64, 0x64,\n",
            "  0x2f, 0x52, 0x65, 0x61, 0x64, 0x56, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c,\n",
            "  0x65, 0x4f, 0x70, 0x2f, 0x72, 0x65, 0x73, 0x6f, 0x75, 0x72, 0x63, 0x65,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0xe2, 0xfc, 0xff, 0xff, 0x00, 0x00, 0x00, 0x09, 0x4c, 0x01, 0x00, 0x00,\n",
            "  0x06, 0x00, 0x00, 0x00, 0x1c, 0x01, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0xd4, 0xfc, 0xff, 0xff, 0xdc, 0x00, 0x00, 0x00, 0xa4, 0x00, 0x00, 0x00,\n",
            "  0x6c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x0d, 0xf8, 0xd5, 0x3b, 0x59, 0xdb, 0xcc, 0x3a,\n",
            "  0xe8, 0x48, 0x55, 0x3c, 0xe6, 0x8d, 0xde, 0x3a, 0x1b, 0x68, 0x04, 0x3b,\n",
            "  0x60, 0x76, 0x93, 0x3c, 0xfe, 0xb0, 0x04, 0x3c, 0x13, 0x53, 0x17, 0x3c,\n",
            "  0x31, 0x70, 0x95, 0x3a, 0x2c, 0xdb, 0xc6, 0x3a, 0xaa, 0x94, 0x40, 0x3c,\n",
            "  0x31, 0xc8, 0xe7, 0x3a, 0x0c, 0x00, 0x00, 0x00, 0xdd, 0x53, 0x0c, 0x3f,\n",
            "  0xdb, 0x3e, 0x6f, 0x3d, 0x56, 0x9e, 0xd3, 0x3f, 0xc2, 0x7e, 0x1b, 0x3e,\n",
            "  0xab, 0x2e, 0x62, 0x3d, 0xd5, 0x64, 0xa4, 0x3f, 0x9c, 0xa7, 0x83, 0x3f,\n",
            "  0x6d, 0x24, 0x96, 0x3f, 0x10, 0x14, 0x51, 0x3d, 0x54, 0x54, 0x57, 0x3d,\n",
            "  0x81, 0x13, 0xbf, 0x3f, 0xfb, 0xec, 0x54, 0x3e, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x1d, 0x4c, 0x54, 0xbf, 0xa2, 0x41, 0x4b, 0xbe, 0x20, 0x36, 0xcc, 0xbf,\n",
            "  0xca, 0xd0, 0x5c, 0xbe, 0x4b, 0x5f, 0x83, 0xbe, 0x73, 0x4f, 0x12, 0xc0,\n",
            "  0x3c, 0x72, 0x34, 0xbf, 0x8c, 0x07, 0x6e, 0xbf, 0x51, 0x45, 0x14, 0xbe,\n",
            "  0x76, 0x4d, 0x45, 0xbe, 0x29, 0xb8, 0x95, 0x3c, 0xa1, 0xf8, 0x65, 0xbe,\n",
            "  0x20, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x5f, 0x32, 0x36, 0x30, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32,\n",
            "  0x64, 0x5f, 0x32, 0x37, 0x30, 0x2f, 0x43, 0x6f, 0x6e, 0x76, 0x32, 0x44,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x4a, 0xfe, 0xff, 0xff, 0x00, 0x00, 0x00, 0x09, 0x6c, 0x00, 0x00, 0x00,\n",
            "  0x05, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x3c, 0xfe, 0xff, 0xff, 0x2c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0xeb, 0xb6, 0x5f, 0x3c, 0x01, 0x00, 0x00, 0x00, 0xe2, 0x07, 0x83, 0x3f,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x7d, 0xf7, 0xdd, 0xbf, 0x1f, 0x00, 0x00, 0x00,\n",
            "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x32,\n",
            "  0x36, 0x30, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x33, 0x30, 0x32,\n",
            "  0x2f, 0x4d, 0x61, 0x74, 0x4d, 0x75, 0x6c, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x0a, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0xca, 0xfe, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x02, 0x44, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xac, 0xff, 0xff, 0xff,\n",
            "  0x28, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x5f, 0x32, 0x36, 0x30, 0x2f, 0x72, 0x65, 0x73, 0x68, 0x61,\n",
            "  0x70, 0x65, 0x5f, 0x31, 0x32, 0x34, 0x2f, 0x52, 0x65, 0x73, 0x68, 0x61,\n",
            "  0x70, 0x65, 0x2f, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x1e, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x02, 0x40, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x04, 0x00, 0x04, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
            "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x32, 0x36, 0x30, 0x2f, 0x66,\n",
            "  0x6c, 0x61, 0x74, 0x74, 0x65, 0x6e, 0x5f, 0x33, 0x30, 0x31, 0x2f, 0x43,\n",
            "  0x6f, 0x6e, 0x73, 0x74, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x6e, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x02,\n",
            "  0x80, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x38, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x61, 0x2c, 0x36, 0x3a, 0x38, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
            "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x32, 0x36, 0x30, 0x2f, 0x64,\n",
            "  0x65, 0x6e, 0x73, 0x65, 0x5f, 0x33, 0x30, 0x32, 0x2f, 0x42, 0x69, 0x61,\n",
            "  0x73, 0x41, 0x64, 0x64, 0x2f, 0x52, 0x65, 0x61, 0x64, 0x56, 0x61, 0x72,\n",
            "  0x69, 0x61, 0x62, 0x6c, 0x65, 0x4f, 0x70, 0x2f, 0x72, 0x65, 0x73, 0x6f,\n",
            "  0x75, 0x72, 0x63, 0x65, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x08, 0x00,\n",
            "  0x07, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x70, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x4c, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x14, 0x00,\n",
            "  0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x2c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x80, 0xff, 0xff, 0xff,\n",
            "  0xff, 0xff, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00, 0x81, 0x80, 0x80, 0x3b,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x3f, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x15, 0x00, 0x00, 0x00, 0x63, 0x6f, 0x6e, 0x76,\n",
            "  0x32, 0x64, 0x5f, 0x32, 0x37, 0x30, 0x5f, 0x69, 0x6e, 0x70, 0x75, 0x74,\n",
            "  0x5f, 0x69, 0x6e, 0x74, 0x38, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00, 0x80, 0x00, 0x00, 0x00,\n",
            "  0x6c, 0x00, 0x00, 0x00, 0x54, 0x00, 0x00, 0x00, 0x38, 0x00, 0x00, 0x00,\n",
            "  0x28, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0xca, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x06, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x07, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x72, 0xc2, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x19,\n",
            "  0x02, 0x00, 0x00, 0x00, 0xf2, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x09,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x0e, 0x00, 0x07, 0x00,\n",
            "  0x00, 0x00, 0x08, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x11,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00, 0x06, 0x00, 0x05, 0x00,\n",
            "  0x06, 0x00, 0x00, 0x00, 0x00, 0x16, 0x0a, 0x00, 0x0c, 0x00, 0x07, 0x00,\n",
            "  0x00, 0x00, 0x08, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03,\n",
            "  0x03, 0x00, 0x00, 0x00\n",
            "};\n",
            "unsigned int MNIST_full_quanitization_tflite_len = 4096;\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvBIhOTI2u1J",
        "colab_type": "text"
      },
      "source": [
        "This file is downloadable from the left hand menu of colab. Although this file is too large to be used as a model on a microcontroller. We will have to do some more optimizations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw7zP9zP80xP",
        "colab_type": "text"
      },
      "source": [
        "Pruning is where unncessart values in weight tensors are removed, thus reducing the number of parameters needed to store the model. This is done by further training the model while intermittently running pruning code that removes unnecessary connections between the layers of the neuran network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rah2i039XJg",
        "colab_type": "code",
        "outputId": "41371082-3c5c-4788-c160-8046548c599f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        }
      },
      "source": [
        "!pip install -q tensorflow-model-optimization\n",
        "\n",
        "import numpy as np \n",
        "import os\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "end_step = np.ceil(1.0 * images_train.shape[0] / batch_size).astype(np.int32) * epochs\n",
        "print(end_step)\n",
        "\n",
        "pruning_params = {\n",
        "    'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.5,\n",
        "                                                 final_sparsity=0.9,\n",
        "                                                 begin_step=0,\n",
        "                                                 end_step=end_step,\n",
        "                                                 frequency=100\n",
        "                                                 )\n",
        "}\n",
        "\n",
        "new_pruned_model = sparsity.prune_low_magnitude(best_model, **pruning_params)\n",
        "new_pruned_model.summary()\n",
        "\n",
        "new_pruned_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "callbacks = [sparsity.UpdatePruningStep(),sparsity.PruningSummaries(log_dir=os.path.abspath(os.getcwd()), profile_batch=0)]\n",
        "\n",
        "new_pruned_model.fit(images_train, labels_train,\n",
        "                     batch_size=batch_size,\n",
        "                     epochs=epochs,\n",
        "                     verbose=1,\n",
        "                     callbacks=callbacks)\n",
        "\n",
        "score = new_pruned_model.evaluate(images_test, labels_test, verbose=0)\n",
        "print(\"Test loss: {}\".format(score[0]))\n",
        "print(\"Test accuracy: {}\".format(score[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000\n",
            "Model: \"sequential_260\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_conv2d_2 (None, 13, 13, 12)        230       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_reshape_ (None, 169, 12, 1)        1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 9, 4, 1)           1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten_ (None, 36)                1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_30 (None, 10)                732       \n",
            "=================================================================\n",
            "Total params: 965\n",
            "Trainable params: 490\n",
            "Non-trainable params: 475\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.6041 - accuracy: 0.8032\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.6561 - accuracy: 0.7853\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.7253 - accuracy: 0.7595\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.7696 - accuracy: 0.7445\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 0.8399 - accuracy: 0.7254\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.8785 - accuracy: 0.7108\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.8934 - accuracy: 0.7045\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.9450 - accuracy: 0.6825\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.9446 - accuracy: 0.6792\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.9340 - accuracy: 0.6821\n",
            "Test loss: 0.8992167711257935\n",
            "Test accuracy: 0.6984999775886536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9ctnEnjAzKu",
        "colab_type": "text"
      },
      "source": [
        "Now we can export the pruned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6oh6ZXXA1BF",
        "colab_type": "code",
        "outputId": "537d92b2-aece-4994-dc46-8c1bd0a20fb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "source": [
        "new_pruned_model.summary()\n",
        "best_model_pruned = sparsity.strip_pruning(new_pruned_model)\n",
        "best_model_pruned.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_260\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_conv2d_2 (None, 13, 13, 12)        230       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_reshape_ (None, 169, 12, 1)        1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 9, 4, 1)           1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten_ (None, 36)                1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_30 (None, 10)                732       \n",
            "=================================================================\n",
            "Total params: 965\n",
            "Trainable params: 490\n",
            "Non-trainable params: 475\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_260\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_270 (Conv2D)          (None, 13, 13, 12)        120       \n",
            "_________________________________________________________________\n",
            "reshape_124 (Reshape)        (None, 169, 12, 1)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_224 (MaxPoolin (None, 9, 4, 1)           0         \n",
            "_________________________________________________________________\n",
            "flatten_301 (Flatten)        (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_302 (Dense)            (None, 10)                370       \n",
            "=================================================================\n",
            "Total params: 490\n",
            "Trainable params: 490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSzcstilCDGL",
        "colab_type": "text"
      },
      "source": [
        "We can compare each pruned weight against zero to see how many weights were pruned out of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKhsXQz6CKCG",
        "colab_type": "code",
        "outputId": "35edb00c-50b3-45cc-b4ca-e9ee5f5e3f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "for i, w in enumerate(best_model_pruned.get_weights()):\n",
        "    print(\"{} -- Total:{}, Zeros: {:.2f}%\".format(\n",
        "        model.weights[i].name, w.size, np.sum(w == 0) / w.size * 100 ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2d_266/kernel:0 -- Total:108, Zeros: 89.81%\n",
            "conv2d_266/bias:0 -- Total:12, Zeros: 0.00%\n",
            "dense_297/kernel:0 -- Total:360, Zeros: 90.00%\n",
            "dense_297/bias:0 -- Total:10, Zeros: 0.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtYoMRRnChQh",
        "colab_type": "text"
      },
      "source": [
        "Same as before we can quantize the model, convert and save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkFxO3jwCrF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(best_model_pruned)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"MNIST_pruned.tflite\", \"wb\").write(tflite_model)\n",
        "!xxd -i MNIST_pruned.tflite > MNIST_pruned.cc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKmWVr-UDCLM",
        "colab_type": "text"
      },
      "source": [
        "Puning saved us"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HWDND29DD3s",
        "colab_type": "code",
        "outputId": "c17e62e4-31cf-45aa-d11b-fdcb0629f618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Quanized file size difference is: {} bytes\".format(os.path.getsize(\"MNIST_model_no_optimizations.tflite\") - os.path.getsize(\"MNIST_full_quanitization.tflite\")))\n",
        "print(\"Pruned file size difference is: {} bytes\".format(os.path.getsize(\"MNIST_full_quanitization.tflite\") - os.path.getsize(\"MNIST_pruned.tflite\")))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quanized file size difference is: 7688 bytes\n",
            "Pruned file size difference is: 0 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqGkaLQ3rfvI",
        "colab_type": "text"
      },
      "source": [
        "As the generated models are so large we need to make sure they are stored in the .rodata segment. To do so the model must be prefixed extern const such that it does not land in the .data segment and kill our ram. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fsVhonWuvV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sed -i '1s/^/extern const /' MNIST_full_quanitization.cc\n",
        "!sed -i '$s/^/extern const /' MNIST_full_quanitization.cc"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}